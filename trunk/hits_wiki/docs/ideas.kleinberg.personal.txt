
Заметки и наброски алгоритмов

Contents

Wikipedia - как использовать энциклопедию в целом для лингвистических исследований.
Kleinberg - идеи по алгоритму поиска синонимов
Category_Kleinberg - как и зачем испльзовать категории
Web_service - получение данных о СБС с помощью веб-сервиса
353 Оценка близости слов

Названия для программы поиска синонимов
synarcher : поиск синонимов synonym search


Wikipedia ====================
1) Cluster Analysis of Taxonomy
Таксономия строится в Wikipedia множеством людей с разным уровнем знаний.
Идея: алгоритм извлекает таксономию из БД, дополняет новыми связями для 
разрешения противоречий (статья без категории, ещё?).
2) Да/Нет - можно сказать для каждой статьи, ответит на вопрос - есть ли 
название статьи в словаре? Т.е. является ли это слово новым или специальным?
Если это новое слово и оно синоним исходному, то оно будет кандидатом для 
добавления в словарь.
3) Построение автоматически иерархии статей (анализируя ссылки + текст).
Оценка классификатора с помощью иерархии, которая составлена вручную пользователями Wikipedia.
=================== Wikipedia

Kleinberg ====================
1) Анализ результатов работы Synonym-Kleinber-Finder.java
2) Поиск вопросов Toeffl с вариантами ответов - синонимы.
3) Оценить качество: написать программу для вычисления качества 
поиска синонимов с пом. этих данных Toeffl.
4) Написать (списать) список русских синонимов для нескольких (всех?) слов.
5) Оценить качество поиска русских синонимов:
    использовать RussNet (кафедра математической лингвистики СПбГУ)
Марина Анна Сергеевна
Азарова Ирина Владимировна

*) Сравнить с другими системами поиска синонимов:
    - http://www.1st-dictionary.com/    - Free Online Dictionary

*) Установить en.wiktionary.org
*) Написать ф-цию проверки, что слово есть в словаре.
*) Выводить вначале те слова (Hubs, authorities), которые есть в wiktionary.
(указывать слова, которые есть в WordNet, но отсутствуют в en.wiktionary)
**) Особо обрабатывать Disambiguation page (see Estate)

**) Поиск и оценка поиска синонимов, когда часть синонимов известна.
Пример: У слова Sugar есть 25 синонимов в WordNet.
Выбрать половину - для обучения алгоритма, другая половина - тестовая, 
т.е. неизвестна.
Изменить алгоритм Kleiberg так, чтобы учитывались синонимы известные априори.
  (Изменение ссылок или величин x, y)
Затем ищем синонимы и сравниваем с тем, что должно быть в WordNet.

**) ?Как использовать слова, помеченные экспертами как синонимы, для улучшения поиска синонимов? 

***) Определение групп синонимов (значений), с пом. категорий.
Постановка задачи: кластеризация графа.
Два типа вершин - статьи и категории.
Три типа ссылок - между статьями, статьями и категориями, между категориями.
Условие: каждый кластер должен содержать исходное слово (синоним).
Задача получить кластеры с максимально удалёнными друг от друга категориями.

Варианты алгоритма:
1) Сначала Kleinber, затем кластеризация.
2) -- '' --    и затем Kleinber для каждого кластера.
3) Сначала кластеризация, затем Kleinber.

Подзадача: выделить ядро, т.е. 1 слово, которое будет именем кластера. 
Найти ореол - слова, наиболее характеризующие кластер.


Category_Kleinberg ===============================================

Предварительная обработка категорий
(Что сделать, чтобы категории можно было использовать в алгоритме поиска синонимов (в кластеризации)):

1) Алгоритм кластеризации статей по кластеризации категорий. 
    - Для каждой вершины v (Статья):
    - обходом в глубину (или ширину) выбрать все категории и статьи, которые ссылаются на эти категории. Получили кластер Cluster(v).
  Недостаток: все категории м.б. связаны между собой. Тогда получим 1 кластер. Большой.

2) Алгоритм определения расстояний между статьями (несвязанными непосредственно?) на основе связей между их категориями.
  1) Определить кратчайшее расстояние между статьями (число переходов по категориям), 
    это будет новым ребром в графе с узлами-статьями (вершины только статьи, а не категории).
  2) Кластеризация этого графа (по темам, т.е. problem domain).
     Какие параметры кластеризации?
     Какие другие графы можно кластеризовать? Здесь предлагается кластеризация: узлы - статьи, рёбра - расстояние от статьи до статьи с помощью категорий.
  3) Поиск синонимов (Hubs & Authorities page) на каждом кластере отдельно.

3) Aлгоритм оптимизации (до кластеризации) (Неудачный т.к. неясно - есть ли необходимость избавляться от висячих, т.е. бесполезных категорий, это всё зависит от алгоритма кластеризации, ещё зависит от характера связок - м.б. все категории связаны в один большой кластер)
  Цель: 
    - Сохранить только те категории, которые связывают какие-либо статьи.
    - Удалить категории, которые связаны только с одной статьей.
  Алгоритм 1 (не реализован):
    - Дано: DCEL=Категории (Category) + Статьи (Articles)
    1. Для каждой статьи a
    2.    для каждой непосредственной категории x (этой статьи а)
    3.        если x помечена (см. шаг 4), то переход к шагу 2.
              иначе
    4.          делаем поиск (в глубину), помечая категории, ищем другие статьи
    5.          если другие статьи не связаны с этими категориями, то
    6.              удаляем все помеченные категории, включая х
    7.          иначе - оставляем пометки.

  Алгоритм 2 (нереализован):
    - Построить дерево кратчайших путей для графа "Статьи + Категории".
    - Пройти все кратчайшие пути Статья-Статья, помечая Категории, через которые проходит путь.
    - Удалить все непомеченные категории.
  Пример:
    Поиск синонимов для слова Плазма. В алгоритме задействовано слово Солнце с двумя категориями Солнце, Солнечная система. Никакие другие слова (задействованные алгоритмом) не связаны с этими двумя категориями.

4) Ошибка. Для Плазмы есть висячая категория "Незавершённые статьи о науке".
Никто на неё не ссылается!
Идея: поиск ошибок в wikipedia.
 
5) Задача: как определить качество кластеризации для сравнения алгоритмов?
- Общее число дуг внутри кластеров и между кластерами (NumEdgeInt и NumEdgeExt).
- Число кластеров.
- Суммарный вес межкластерных ребер SumWeightEdgeExt. Цель - его минимизация. Но не ясно, действительно ли минимум говорит о качественной кластеризации?
- Неравномерность разбиения: отклонение (модуль, невязка) от идеального равномерного разбиения.

6) Алгоритм кластеризации категорий и статей (реализован).
Данные
  ребро е, поля е.c1 и е.c2 - указатели на две соединяемые вершины (кластеры);
                e.weight    - вес ребра (пересчитывается) равен суммарному весу объединяемых кластеров с1 и с2.
  кластер-вершина с 
           поля // с.n_edges    - число объединённых рёбер кластера (рёбер между вершинами-категориями кластера).
                c.n_articles - число статей, которые ссылаются на категории в кластере. Это составляющая веса кластера
                c.weight    - вес (размер) кластера
                c.edges     - массив рёбер (указателей), которые связывают кластер с другими кластерами

Предобработка.
*  1.0 Константы
*      MaxClusterWeight - максимально разрешённый размер кластера
*  1.1 Построить кластеры (массив Clusters) по категориям: изначально каждый кластер соответствует 
* отдельной вершине (категории). Приписать каждому кластеру (за счёт содержащихся в кластере категорий):
*      1) c.n_articles = число статей, которые ссылаются на категории в кластере. Это составляющая веса кластера
*      2) c.weight = 1 + n_article  REM вес кластера - это число категорий в кластере (изначально 1) и число статей, которые ссылаются на эту одну категорию; 
*      3) c.category_id[0] = id     REM присваиваем id первой (и единственной пока) категории, добавленной в кластер.
*  1.2 Для каждого ребра между категориями создать ребро между кластерами. Каждому ребру, соединяющему два кластера c1 и c2 вес e.weight так:
          e.weight = c1.weight + c2.weight

Алгоритм.
  1) ARRAY ESorted = sort(e.weight)     REM Сортировка рёбер по весу. ESorted[0] - ребро с минимальным весом.
  2) while( ESorted <> 0 && (ESorted[0] < MaxClusterWeight)) BEGIN
  3)    e = ESorted[0]                  REM v1,v2 - две вершины ребра e 
  4)    ESorted = ESorted \ AdjacentEdges(v2) REM удалить из упорядоченного массива рёбер рёбра смежные v2
  5)    Merge(e);       REM объединить вершины-кластеры v1 и v2 в кластер v1, т.е. добавить вершину v2 в кластер v1, т.о. изменили свойства v1:
            v1.weight += v2.weight      REM увеличили размер кластера (число категорий и статей)
            v1.n_articles += v.n_articles REM увеличили число статей
            v1.n_edges += v2.n_edges    REM увеличили число рёбер
            v1.category_id[] += addUnique(v2.category_id[]) REM добавили категории без повторов
            passEdges()                 REM все рёбра смежные вершине v2 передать вершине v1 (рёбра без повторений, т.к. это не мультграф).
            remove edge (v1, v2)
            updateEdgesOfMergedCluster  REM (Обновить указатели на вершины)/(удалить ребра), смежные удаляемой вершине
            updateEdgeWeight(v1)        REM пересчитать значения весов для всех рёбер смежных v1
            remove(Clusters, v2)        REM удалить кластер v2 из массива кластеров
        ESorted = sort(e.weight)        REM пересортировка рёбер, сложность O(N), т.к. нужно обновить порядок только тех рёбер, которые смежны вершине v1
  6) END 
  7) Return Clusters                    REM вернуть список полученных кластеров.
 
Результат - это кластеры категорий. По кластеру категорий получаем кластер статей.
Замечание: Здесь не используется информация о связях (ссылками) между статьями.

Замечание: 
1) Одна статья может ссылаться на несколько категорий. Поэтому одна статья может принадлежать нескольким кластерам. Но категория принадлежит ровно одному кластеру.

Web_service ==============================================
Web_service - получение данных о СБС с помощью веб-сервиса

Реализация: 

0) веб-сервис 0
Вход: название статьи ВП. (опционально параметры AHITS)
Выход: структура графа, упорядоченный список слов близких по смыслу.

1) веб-сервис 1.
Вход: название статьи ВП. (опционально параметры AHITS)
Выход: упорядоченный список слов близких по смыслу.

2) веб-сервис 2.
Вход: название двух статей ВП.
Выход: число - степень сходства.

353 Оценка близости слов ================================

Идея пришла, когда читал ijcai-2007-sim.pdf, после сна.

У Габриловича
2. На вход подаются два текста. По ним строятся два вектора из концептов ВП. Для сравнения текстов сравнивают два вектора, например, с помощью косинусного коэффициента.

У меня
АКА: вектор строится с помощью AHITS. Т.е. можно использовать AHITS для вычисления расстояний между концептами ВП.
Вычислить расстояние между 353 парами синонимов, чтобы сравнить с WordNet, WikiRelate!, ESA.
Title: Search for related terms in WP by Adapted HITS algorithm.

Дополнительный шаг к АHITS:
*prev) пусть уже построили список синонимов (авторитетных страниц) для концепта, т.е. вектор концептов ВП для исходного слова.

*новый шаг 1) выполнить AHITS для каждого синонима из списка и построить N векторов.
*2) сравнить с помощью косин. коэф. эти вектора с вектором исходного слова, упорядочить вектора (а значит и слова им соответствующие) по степени сходства.

Получили упорядоченный список семантически близких слов. Можно сравнить со списком экспертов и сказать - зряшный этот последний шаг или нет.



